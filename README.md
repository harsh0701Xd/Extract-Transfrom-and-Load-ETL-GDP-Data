# Web scraping using Pandas

## Introduction

In this practice project, we aim to create a ETL (Extract, Transform, Load) pipeline for accessing data from a website, processing it, and storing it in CSV format. The project scenario involves retrieving GDP data from a Wikipedia page and formatting it according to specific requirements.

### Project Overview

An international firm is expanding its business globally and requires an automated script to extract GDP data from a Wikipedia page maintained by the International Monetary Fund (IMF). The script must then transform this data into a consistent format and store it in CSV formats.

### Project Tasks:

1. **Data Extraction:** Retrieve relevant information from the specified URL.
2. **Data Transformation:** Convert GDP information from million USD to billion USD and round to 2 decimal places.
3. **Data Loading:** Save the transformed data to CSV formats.

### Prerequisites

Ensure you have the following libraries installed:

- `pandas`
- `numpy`

## Results

### Raw Data

![Raw Data Screenshot](https://cf-courses-data.s3.us.cloud-object-storage.appdomain.cloud/IBMDeveloperSkillsNetwork-PY0101EN-SkillsNetwork/images/pandas_wbs_3.png)

### Preprocessed Data

![Preprocessed Data Screenshot](https://github.com/harsh0701Xd/Extract-Transfrom-and-Load-GDP-Data/assets/89227170/0c0d8469-4c24-41bf-b54a-9d9e932a26d0)


